---
author: Esa Eslami
date: 7/8/2018
title: "COMPSCIX 415.2 Homework 5/Midterm"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    toc_depth: 3
---
My Github repository for my assignments can be found at this URL: [https://github.com/esaeslami/compscix-415-2-assignments](https://github.com/esaeslami/compscix-415-2-assignments)

```{r load_packages, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)

```

##__Midterm Exercises__##

### RStudio and R Markdown

*1. Use markdown headers in your document to clearly separate each midterm question and add a table of
contents to your document.*

__ANSWER:__ See document formatting.

* * *

### The tidyverse packages

*By now you’ve used at least five different packages from the tidyverse for plotting, data munging, reshaping data, importing/exporting data, and using tibbles (the tibble package is used for this without you even realizing it’s there).*

*1. Can you name which package is associated with each task below?*

__ANSWER:__ 

* Plotting - __ggplot2__
* Data munging/wrangling - __dplry__
* Reshaping (speading and gathering) data - __tidyr__
* Importing/exporting data - __readr__

* * *

*2. Now can you name two functions that you’ve used from each package that you listed above for these tasks?*

__ANSWER:__ 

* Plotting - __ggplot(), geom_point()__ 
* Data munging/wrangling - __select(), filter()__ 
* Reshaping (speading and gathering) data - __gather(), spread()__ 
* Importing/exporting data - __read_csv(), write_csv()__ 

* * *

### R Basics

*1. Fix this code with the fewest number of changes possible so it works:*

```{r rbasics_q1, warning=FALSE, message=FALSE, eval=FALSE}
My_data.name___is.too00ooLong! <- c( 1 , 2 , 3 )
```

__ANSWER:__ The code will work if you simply remove the exclamation point:

```{r rbasics_a1, warning=FALSE, message=FALSE}
# This vector name is still very bad
My_data.name___is.too00ooLong <- c( 1 , 2 , 3 )
# See contents of new vector
My_data.name___is.too00ooLong
```
* * *

*2. Fix this code so it works:*

```{r rbasics_q2, warning=FALSE, message=FALSE, eval=FALSE}
my_string <- C('has', 'an', 'error', 'in', 'it)
```

__ANSWER:__ The c() needs to be lowercase and the last value needs a second quotation mark:

```{r rbasics_a2, warning=FALSE, message=FALSE}
# Corrected code
my_string <- c('has', 'an', 'error', 'in', 'it')
# See contents of new vector
my_string
```
* * *

*3. Look at the code below and comment on what happened to the values in the vector.*

```{r rbasics_q3, warning=FALSE, message=FALSE}
my_vector <- c(1, 2, '3', '4', 5)
my_vector
```

__ANSWER:__ Because 3 and 4 were entered as characters, all values of the vector were converted to character as well. 

* * *

### Data import/export

*1. Download the rail_trail.txt file from Canvas (in the Midterm Exam section) and successfully import it into R. Prove that it was imported successfully by including your import code and taking a glimpse of the result.*

__ANSWER:__ 

```{r import_export_a1, warning=FALSE, message=FALSE}
#Set file path equal to location of rail_trail.txt file  
rail_trail_path <- 'C:/Users/Eeslami/Desktop/UCB Courses/X415.2 - Introduction to Data Science/compscix-415-2-assignments/rail_trail.txt'
#Load rail_trail.txt file into R 
rail_trail_df <- read_delim(file = rail_trail_path, delim = '|')
#Look at data to make sure it loaded correctly
glimpse(rail_trail_df)
```

* * *

*2. Export the file into a comma-separated file and name it “rail_trail.csv”. Make sure you define the path correctly so that you know where it gets saved. Then reload the file. Include your export and import code and take another glimpse.*

__ANSWER:__ 

```{r import_export_a2, warning=FALSE, message=FALSE}
#Export rail_trail_df as ‘rail_trail.csv’
write_delim(rail_trail_df, delim = ',', path = 'C:/Users/Eeslami/Desktop/UCB Courses/X415.2 - Introduction to Data Science/compscix-415-2-assignments/rail_trail.csv')
#Reload rail_trail.csv 
rail_trail_df2 <- read.csv(file = 'rail_trail.csv')
#Look at data to make sure it loaded correctly
glimpse(rail_trail_df2)
```

* * *

### Visualization

*1. Critique this graphic. Give only three examples of what is wrong with this graphic. Be concise.*

![](C:/Users/Eeslami/Desktop/UCB Courses/X415.2 - Introduction to Data Science/compscix-415-2-assignments/mrspresident.jpg) 
 
__ANSWER:__ 

1. The graphic mixes age and gender on the vertical axis, which initially makes you think there are five mutually exclusive values when there are not. 
2. The color coding initially makes you think there is some significance to the bottom two rows, but they are just arbitrarily using color for the male/female rows. 
3. The age rows are presented in a counter-intuitive order, with older ages appearing lower than younger ages. 

* * *

*2. Reproduce this graphic using the diamonds data set.*

![](C:/Users/Eeslami/Desktop/UCB Courses/X415.2 - Introduction to Data Science/compscix-415-2-assignments/caratofdiamond.png) 

__ANSWER:__  
```{r visualization_a2, warning=FALSE, message=FALSE}
ggplot(data = diamonds, mapping = aes(x = cut,y = carat, fill = color)) + 
  geom_boxplot(position = 'identity') +
  coord_flip() +
  xlab("CUT OF DIAMOND") +
  ylab("CARAT OF DIAMOND")
```

* * *

*3. The previous graphic is not very useful. We can make it much more useful by changing one thing about it. Make the change and plot it again.*

__ANSWER:__  The graphic above places all of the color histograms on top of each other so that it is impossible to distinguish much difference by color. Changing position to "dodge" will greatly improve the plot.
```{r visualization_a3, warning=FALSE, message=FALSE}
ggplot(data = diamonds, mapping = aes(x = cut,y = carat, fill = color)) + 
  geom_boxplot(position = 'dodge') +
  coord_flip() +
  xlab("CUT OF DIAMOND") +
  ylab("CARAT OF DIAMOND")
```

* * *
### Data munging and wrangling

*1. Is this data “tidy”? If yes, leave it alone and go to the next problem. If no, make it tidy.*

```{r munging_wrangling_q1, warning=FALSE, message=FALSE}
table2
```

__ANSWER:__ No. The type column contains two different variables (cases and population), therefore the data is not shown in the most intuitive or useful way. To clean this up, you can use the spread() fuction to break out type into two new rows, like this: 

```{r munging_wrangling_a1, warning=FALSE, message=FALSE}
table2 %>%
    spread(key = type, value = count)
```

* * *

*2. Create a new column in the diamonds data set called price_per_carat that shows the price of each diamond per carat (hint: divide). Only show me the code, not the output.*

__ANSWER:__  

```{r munging_wrangling_a2, warning=FALSE, message=FALSE, eval=FALSE}
mutate(diamonds,
  price_per_carat = price / carat
)
```

* * *

*3. For each cut of diamond in the diamonds data set, how many diamonds, and what proportion, have a price > 10000 and a carat < 1.5? There are several ways to get to an answer, but your solution must use the data wrangling verbs from the tidyverse in order to get credit.*

*• Do the results make sense? Why?*

*• Do we need to be wary of any of these numbers? Why?*

__ANSWER:__  

```{r munging_wrangling_a3, warning=FALSE, message=FALSE}
diamonds %>%
  group_by(cut) %>% 
  summarise(total_diamonds = n(),
            high_price_low_carat = sum(price > 10000 & carat < 1.5),
            proportion_of_total = mean(price > 10000 & carat < 1.5))
```

The results make sense in that as the cut quality increases, there are more diamonds meeting the high price cut off (>$10,000). We would maybe expect that not as many Ideal diamonds would qualify under the low carat threshold (< 1.5), but this is a good example that carat is not the only driver in price. To get a better sense of what's going on here, we would want to add another variable to our output. 

* * *

### EDA

*Take a look at the txhousing data set that is included with the ggplot2 package and answer these questions:*

*1. During what time period is this data from?*

__ANSWER:__ The date spans January 2000 to July 2015.
```{r EDA_a1, warning=FALSE, message=FALSE}
# See the earliest date
txhousing %>%
  select(year, month, date) %>%
  arrange(date) %>%
  head(1)
# See the latest date
txhousing %>%
  select(year, month, date) %>%
  arrange(desc(date)) %>%
  head(1)
```


* * *

*2. How many cities are represented?*

__ANSWER:__ There are 46 cities represented.
```{r EDA_a2, warning=FALSE, message=FALSE}
txhousing %>%
  summarise(Unique_Cities = n_distinct(city))
```

* * *

*3. Which city, month and year had the highest number of sales?*

__ANSWER:__ The highest number of sales occured in Houston in July 2015.
```{r EDA_a3, warning=FALSE, message=FALSE}
txhousing %>%
  select(city, month, year, sales) %>%
  arrange(desc(sales)) %>%
  head(1)
```

* * *

*4. What kind of relationship do you think exists between the number of listings and the number of sales? Check your assumption and show your work.*

__ANSWER:__ It appears that as listings increase, so do sales. This relationship is not exactly linear though, and it's likely that other factors are in play (such as city).
```{r EDA_a4, warning=FALSE, message=FALSE}
ggplot(data = txhousing, mapping = aes(x = listings, y = sales)) + 
  geom_point() +
  geom_smooth(se = FALSE)
```

* * *

*5. What proportion of sales is missing for each city?*

__ANSWER:__ Most cities are missing only a few sales. However, there are a few standouts. South Padre Island and Kerrville are both missing over half of their sales, and a few others are missing between 10 to 40 percent of their sales. 
```{r EDA_a5, warning=FALSE, message=FALSE}
txhousing %>%
  group_by(city) %>% 
  summarise(total_sales = n(),
            missing_sales = sum(is.na(sales)),
            prop_missing = missing_sales/total_sales) %>%
  arrange(desc(prop_missing)) 
```

* * *

*6. Looking at only the cities and months with greater than 500 sales:*

* Are the distributions of the median sales price (column name median), when grouped by city, different? The same? Show your work.

__ANSWER:__ The distributions vary by city:
```{r EDA_a6_1, warning=FALSE, message=FALSE}
sales_over_500_df <- filter(txhousing, sales > 500)
ggplot(data = sales_over_500_df, mapping = aes(x = reorder(city, median, fun = median), y = median)) + 
  geom_boxplot() +
  coord_flip() +
  xlab("City") +
  ggtitle("Median housing sales ($) for cities with over 500 sales in a month")
```

* Any cities that stand out that you’d want to investigate further?

__ANSWER:__ Yes, it would be interesting to get more information on the cities that appear at the top of the graph to see why their housing market is doing so well. It may be regional aspect, or reflective of the population living there already. 

* Why might we want to filter out all cities and months with sales less than 500?

__ANSWER:__ Because we are interested in identifying high sales markets, we want to eliminate any cities with potential outlier sales months. Average sales are about 550 per month, over the entire data set, so a cut off of 500 makes sense. And while the median is much lower (at 169), there are so many cities represented that we want to pick a number high enough (like 500) so that we limit our analysis on the top housing markets.   
```{r EDA_a6_2, warning=FALSE, message=FALSE}
summary(txhousing$sales, na.rm = TRUE)
```
* * *